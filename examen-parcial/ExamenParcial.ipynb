{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Examen: Análisis Morfológico con NLTK**\n",
        "\n",
        "Robert Adrian Bustamante Arratia"
      ],
      "metadata": {
        "id": "HM8IqV9pf8oJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.tokenize import TreebankWordTokenizer\n",
        "from nltk.tag import UnigramTagger, DefaultTagger\n",
        "from nltk.corpus import cess_esp\n",
        "\n",
        "# Descargar corpus español de NLTK\n",
        "# Este corpus se usa para entrenar el tagger en español, contiene frases etiquetadas morfosintácticamente\n",
        "nltk.download('cess_esp')\n",
        "\n",
        "# Tokenizador simple que funciona en Colab y evita el error 'punkt_tab'\n",
        "# TreebankWordTokenizer separa palabras y puntuación\n",
        "tokenizer = TreebankWordTokenizer()\n",
        "\n",
        "# Entrenar tagger unigram con backoff\n",
        "# El tagger principal aprende del corpus cess_esp\n",
        "# El tagger de respaldo (DefaultTagger) asigna VERB si no reconoce la palabra\n",
        "# Esto es necesario porque palabras como \"salta\" no están en el corpus\n",
        "train_sents = cess_esp.tagged_sents()\n",
        "default_tagger = DefaultTagger('VERB')\n",
        "tagger = UnigramTagger(train_sents, backoff=default_tagger)\n",
        "\n",
        "# Diccionario para mapear etiquetas de cess_esp a etiquetas universales simples\n",
        "# Justificación: el examen pide etiquetas como DET, NOUN, VERB, etc.\n",
        "# Pero el corpus tiene etiquetas detalladas como 'da0ms0', 'vmip3s0', etc.\n",
        "# Aquí hacemos un mapeo aproximado a etiquetas universales, sin inventar etiquetas\n",
        "mapa_pos = {\n",
        "    'da': 'DET',    # determinantes\n",
        "    'nc': 'NOUN',   # sustantivos comunes\n",
        "    'aq': 'ADJ',    # adjetivos calificativos\n",
        "    'vm': 'VERB',   # verbos principales\n",
        "    'rg': 'ADV',    # adverbios\n",
        "    'cc': 'CCONJ',  # conjunciones coordinadas\n",
        "    'cs': 'SCONJ',  # conjunciones subordinadas\n",
        "    'sp': 'ADP',    # preposiciones\n",
        "    'F': 'PUNCT',   # signos de puntuación\n",
        "    'X': 'VERB'     # respaldo para palabras desconocidas\n",
        "}\n",
        "\n",
        "def map_pos(tag):\n",
        "    \"\"\"\n",
        "    Mapea etiquetas morfosintácticas del corpus a etiquetas universales.\n",
        "    Notas:\n",
        "    - tag[:2] toma los primeros dos caracteres porque identifican la categoría general\n",
        "    - Si la palabra no está en el tagger, asignamos 'X' y luego la mapeamos a VERB\n",
        "    \"\"\"\n",
        "    if tag is None:\n",
        "        return 'X'\n",
        "    return mapa_pos.get(tag[:2], 'X')\n",
        "\n",
        "def analisis_morfologico(oracion):\n",
        "    \"\"\"\n",
        "    Realiza un análisis morfológico legítimo en español usando NLTK.\n",
        "    Justificación de decisiones:\n",
        "    1. Se tokeniza con TreebankWordTokenizer porque punkt_tab no existe en Colab.\n",
        "    2. Las palabras se pasan a minúsculas para mejorar el reconocimiento en el tagger.\n",
        "    3. Se utiliza un UnigramTagger entrenado en cess_esp + DefaultTagger de respaldo.\n",
        "       Esto evita que palabras como \"salta\" queden sin etiqueta.\n",
        "    4. Se hace un mapeo de etiquetas del corpus a etiquetas universales como pide el examen.\n",
        "       No copiamos directamente las etiquetas del ejemplo, porque eso sería trampa.\n",
        "    \"\"\"\n",
        "    # Tokenización\n",
        "    tokens = tokenizer.tokenize(oracion)\n",
        "\n",
        "    # Total de tokens\n",
        "    total_tokens = len(tokens)\n",
        "\n",
        "    # Total de tipos únicos (vocabulario)\n",
        "    total_tipos = len(set(tokens))\n",
        "\n",
        "    # Ratio tipo-token\n",
        "    ratio_tt = round(total_tipos / total_tokens, 3) if total_tokens > 0 else 0\n",
        "\n",
        "    # Etiquetado POS usando minúsculas para mejorar coincidencia en el tagger\n",
        "    pos_tags_raw = tagger.tag([t.lower() for t in tokens])\n",
        "\n",
        "    # Mapear etiquetas a etiquetas universales simples\n",
        "    pos_tags = [(token, map_pos(tag)) for token, (_, tag) in zip(tokens, pos_tags_raw)]\n",
        "\n",
        "    return {\n",
        "        'total_tokens': total_tokens,\n",
        "        'total_tipos': total_tipos,\n",
        "        'ratio_tt': ratio_tt,\n",
        "        'pos_tags': pos_tags\n",
        "    }\n",
        "\n",
        "# Prueba\n",
        "oracion_ejemplo = \"El gato negro salta alto y el perro corre rápido por el parque.\"\n",
        "resultado = analisis_morfologico(oracion_ejemplo)\n",
        "print(resultado)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2SxQnXUoVhan",
        "outputId": "e7518631-26d5-43f4-a825-31e41cbade1f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package cess_esp to /root/nltk_data...\n",
            "[nltk_data]   Package cess_esp is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'total_tokens': 14, 'total_tipos': 13, 'ratio_tt': 0.929, 'pos_tags': [('El', 'DET'), ('gato', 'NOUN'), ('negro', 'ADJ'), ('salta', 'X'), ('alto', 'ADJ'), ('y', 'CCONJ'), ('el', 'DET'), ('perro', 'NOUN'), ('corre', 'VERB'), ('rápido', 'ADJ'), ('por', 'ADP'), ('el', 'DET'), ('parque', 'NOUN'), ('.', 'X')]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "**El análisis del resultado**\n",
        "\n",
        "\n",
        "es legítimo y funcional con resultados coherentes talvez no los mismos que se esperaban ya que las diferencias con la salida del examen se deben principalmente porque hay limitaciones del corpus de entrenamiento como tambiuen la necesidad de mapear etiquetas a un conjunto universal simplificado.\n"
      ],
      "metadata": {
        "id": "BTdRWYxWkw0p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Justificación del porque no seguimos tan a paso las instrucciones**\n",
        "\n",
        "Primero tome la decision de no utilizar directamente nltk.pos_tag() ya que la principal razon de esta decision es que en el entorno de Google Colab este recurso no esta disponible de forma oficial en NLTK y su uso puede generar errores de descarga o de compatibilidad las cuales tuvimos y habia una alternativa de spaCy pero como el examen especificamente dijo NLTK obte por soluciones por lo tanto usarlo directamente habría comprometido la ejecución correcta y reproducible del análisis.\n",
        "\n",
        "En lugar de ello se implemento una solución legítima y funcional usando recursos disponibles de NLTK concretamente:\n",
        "\n",
        "Corpus cess_esp: Se utilizó este corpus de español etiquetado morfosintácticamente para entrenar un UnigramTagger, permitiendo que el análisis de POS se realizara de manera confiable sobre textos en español.\n",
        "\n",
        "DefaultTagger de respaldo: Se añadio un tagger de respaldo que asigna la etiqueta 'VERB' a palabras desconocidas asegurando que palabras comunes conjugadas como salta o corre reciban una etiqueta valida incluso si no estan presentes en el corpus pero aun se tiene ese error en x ya que salta no puede estar talvez en su diccionario\n",
        "\n",
        "Mapeo de etiquetas a un conjunto universal: El corpus cess_esp utiliza etiquetas morfosintácticas detalladas como 'da0ms0' o 'vmip3s0'. Para que sea como el examen pidio (DET, NOUN, ADJ, VERB, ADV, CCONJ, ADP, PUNCT) se implemento un diccionario de mapeo que traduce estas etiquetas a un conjunto de POS universales Esto permite mantener la coherencia con el ejemplo de salida sin manipular manualmente los resultados\n",
        "\n",
        "Tokenización robusta con TreebankWordTokenizer: Se eligió este tokenizador en lugar de nltk.word_tokenize() para español ya que evita errores relacionados con punkt_tab y permite separar correctamente palabras y puntuación garantizando que el conteo de tokens y tipos sea exacto.\n",
        "\n",
        "En consecuencia se añadieron funciones auxiliares (map_pos) y se aplicaron técnicas como backoff en el tagger y normalización a minusculas para el etiquetado. Estas decisiones se tomaron para asegurar que\n",
        "\n",
        "El análisis fuera completamente funcional en el entorno de Colab sin depender de recursos no disponibles.\n",
        "\n",
        "Los resultados fueran consistentes y reproducibles respetando la estructura solicitada en el examen\n",
        "\n",
        "\n",
        "Aunque no sigo la solución del examen al pie de la letra el paso a paso indicado en el examen todas las modificaciones realizadas son técnicamente justificadas\n",
        "SI TABA COMPLICADO :´v"
      ],
      "metadata": {
        "id": "6Da6QyLCiEwy"
      }
    }
  ]
}