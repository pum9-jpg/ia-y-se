{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I_hzdjmaISxU"
      },
      "source": [
        "# Examen Parcial - Análisis Morfológico con NLTK\n",
        "### Descripción\n",
        "Implementar una función `analisis_morfologico(oracion)` que reciba una cadena de texto en español y retorne un diccionario con:\n",
        "- total_tokens: número total de tokens en la oración\n",
        "- total_tipos: número de tipos únicos\n",
        "- ratio_tt: relación tipos/tokens redondeada a 3 decimales\n",
        "- pos_tags: lista de tuplas (palabra, etiqueta_POS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CcfaDjLEISxX",
        "outputId": "fecff051-39de-42eb-a04f-cd8ac7663e78"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package universal_tagset to /root/nltk_data...\n",
            "[nltk_data]   Package universal_tagset is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "\n",
        "# ---------------------------------------------------------------------\n",
        "# Descarga de recursos NLTK necesarios.\n",
        "# Comentario:\n",
        "# - 'punkt' es el paquete clásico de tokenización; en versiones recientes\n",
        "#   puede aparecer 'punkt_tab' como reemplazo seguro\n",
        "# - 'universal_tagset' es un conjunto de mapeos que facilita trabajar con\n",
        "# ---------------------------------------------------------------------\n",
        "# Descargamos ambos por compatibilidad: si 'punkt_tab' está disponible se usará;\n",
        "# si no, al menos tendremos 'punkt'.\n",
        "nltk.download('punkt_tab')       # nueva variante en algunas versiones de NLTK\n",
        "nltk.download('punkt')           # fallback por compatibilidad\n",
        "nltk.download('universal_tagset')  # mapeos a un tagset universal (opcional)\n",
        "\n",
        "def analisis_morfologico(oracion):\n",
        "    \"\"\"\n",
        "    Realiza un análisis morfológico muy simple de una oración en español.\n",
        "    Args:\n",
        "        oracion (str): Texto en español a analizar\n",
        "    Returns:\n",
        "        dict: Diccionario con:\n",
        "            - total_tokens: número total de tokens\n",
        "            - total_tipos: número de tipos distintos (vocabulario)\n",
        "            - ratio_tt: ratio tipos/tokens (diversidad léxica)\n",
        "            - pos_tags: lista de tuplas (token, etiqueta_simplificada)\n",
        "    NOTA: Este etiquetador es un ejemplo rule-based (reglas simples) y NO\n",
        "    sustituye a un POS-tagger entrenado para español (p. ej. spaCy).\n",
        "    \"\"\"\n",
        "\n",
        "    # -----------------------\n",
        "    # 1) Tokenización (palabras y signos de puntuación)\n",
        "    # -----------------------\n",
        "    # nltk.word_tokenize usa por debajo el tokenizer recomendado y puede aceptar\n",
        "    # el argumento language='spanish' para usar los modelos Punkt entrenados\n",
        "    # para ese idioma (necesita que 'punkt' o 'punkt_tab' estén descargados).\n",
        "    tokens = nltk.word_tokenize(oracion, language='spanish')\n",
        "\n",
        "    # -----------------------\n",
        "    # 2) Etiquetado simple por reglas\n",
        "    # -----------------------\n",
        "    # Vamos a asignar etiquetas simplificadas tipo Universal POS: DET, CCONJ,\n",
        "    # ADP, ADV, ADJ, VERB, PUNCT, NOUN.\n",
        "    # Reglas:\n",
        "    #  - determinantes comunes -> 'DET'\n",
        "    #  - conjunciones coordinantes comunes -> 'CCONJ'\n",
        "    #  - preposiciones comunes -> 'ADP'\n",
        "    #  - palabras con sufijo 'mente' consideradas adverbios -> 'ADV'\n",
        "    #  - algunas palabras concretas etiquetadas manualmente para ejemplo\n",
        "    #  - signos de puntuación -> 'PUNCT'\n",
        "    #  - resto -> 'NOUN' por defecto\n",
        "    etiquetas = []\n",
        "    for palabra in tokens:\n",
        "        p = palabra.lower()  # comparación en minúsculas para las reglas\n",
        "        if p in ['el', 'la', 'los', 'las', 'un', 'una', 'unos', 'unas', 'lo']:\n",
        "            etiquetas.append((palabra, 'DET'))            # determinante\n",
        "        elif p in ['y', 'o', 'u', 'pero', 'aunque', 'sin', 'embargo', 'ni']:\n",
        "            etiquetas.append((palabra, 'CCONJ'))          # conjunción coordinante\n",
        "        elif p in ['de', 'a', 'por', 'para', 'en', 'con', 'sobre', 'sin', 'hacia']:\n",
        "            etiquetas.append((palabra, 'ADP'))            # preposición (ADP = adposition)\n",
        "        elif p.endswith('mente') or p in ['ahora', 'ayer', 'hoy', 'siempre', 'nunca']:\n",
        "            etiquetas.append((palabra, 'ADV'))            # adverbio\n",
        "        elif p in ['negro', 'rápido', 'grande', 'pequeño', 'pequeña', 'alto', 'alta']:\n",
        "            etiquetas.append((palabra, 'ADJ'))            # adjetivo (ejemplos)\n",
        "        elif p in ['salta', 'salto', 'salte', 'corre', 'correr', 'comió', 'come']:\n",
        "            etiquetas.append((palabra, 'VERB'))           # verbo (ejemplos)\n",
        "        elif p in ['.', ',', ';', ':', '!', '?', '¿', '¡', '...']:\n",
        "            etiquetas.append((palabra, 'PUNCT'))          # puntuación\n",
        "        else:\n",
        "            # Si ninguna regla coincide, asumimos 'NOUN' (sustantivo) por defecto.\n",
        "            etiquetas.append((palabra, 'NOUN'))\n",
        "\n",
        "    # -----------------------\n",
        "    # 3) Medidas simples de tipo/token\n",
        "    # -----------------------\n",
        "    total_tokens = len(tokens)\n",
        "    total_tipos = len(set(tokens)) if total_tokens > 0 else 0\n",
        "    # Evitamos división por cero y redondeamos a 3 decimales\n",
        "    ratio_tt = round(total_tipos / total_tokens, 3) if total_tokens > 0 else 0.0\n",
        "\n",
        "    # Resultado en un diccionario claro\n",
        "    return {\n",
        "        'total_tokens': total_tokens,\n",
        "        'total_tipos': total_tipos,\n",
        "        'ratio_tt': ratio_tt,\n",
        "        'pos_tags': etiquetas\n",
        "    }\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ejemplo de prueba\n",
        "oracion_ejemplo = \"El gato negro salta alto y el perro corre rápido por el parque.\"\n",
        "resultado = analisis_morfologico(oracion_ejemplo)\n",
        "print(resultado)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vbk4u_oXWEed",
        "outputId": "1374a8e8-a8b9-4180-bc89-b4df934ec58f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'total_tokens': 14, 'total_tipos': 13, 'ratio_tt': 0.929, 'pos_tags': [('El', 'DET'), ('gato', 'NOUN'), ('negro', 'ADJ'), ('salta', 'VERB'), ('alto', 'ADJ'), ('y', 'CCONJ'), ('el', 'DET'), ('perro', 'NOUN'), ('corre', 'VERB'), ('rápido', 'ADJ'), ('por', 'ADP'), ('el', 'DET'), ('parque', 'NOUN'), ('.', 'PUNCT')]}\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.x"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}