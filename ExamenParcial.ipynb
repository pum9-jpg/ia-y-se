{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# CELDA 1: Preparaci√≥n del entorno (comprobaci√≥n/descarga segura de recursos NLTK)\n",
        "import nltk\n",
        "\n",
        "def asegurar_recurso(recurso_path, nombre_paquete):\n",
        "    \"\"\"\n",
        "    Comprueba si existe el recurso en nltk.data; si no, lo descarga.\n",
        "    recurso_path: ruta usada por nltk.data.find (ej: 'tokenizers/punkt')\n",
        "    nombre_paquete: nombre usado en nltk.download (ej: 'punkt')\n",
        "    \"\"\"\n",
        "    import nltk.data\n",
        "    try:\n",
        "        nltk.data.find(recurso_path)\n",
        "        # recurso ya disponible\n",
        "        # print(f\"Recurso '{nombre_paquete}' ya disponible.\")\n",
        "    except LookupError:\n",
        "        print(f\"Descargando recurso NLTK: {nombre_paquete} ...\")\n",
        "        nltk.download(nombre_paquete, quiet=False)\n",
        "\n",
        "# Aseguramos tokenizador y tagger (se descargan solo si faltan)\n",
        "asegurar_recurso('tokenizers/punkt', 'punkt')\n",
        "asegurar_recurso('taggers/averaged_perceptron_tagger', 'averaged_perceptron_tagger')\n",
        "\n",
        "print(\"‚úÖ Recursos NLTK comprobados/descargados si fue necesario.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2vbRvXQBk8sG",
        "outputId": "1399852c-807c-465a-949f-ff09a238e40a"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Recursos NLTK comprobados/descargados si fue necesario.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CELDA 2: Importaciones\n",
        "from nltk import word_tokenize, pos_tag\n",
        "from pprint import pprint\n",
        "\n",
        "print(\"‚úÖ Importaciones completadas.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kttGf9AjjXY-",
        "outputId": "f8904e44-5ac0-47d5-f637-64bd5dbc6ffe"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Importaciones completadas.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CELDA 3: Implementaci√≥n de analisis_morfologico (robusta)\n",
        "def analisis_morfologico(oracion):\n",
        "    \"\"\"\n",
        "    Realiza an√°lisis morfol√≥gico (tokens, tipos, ratio tipo/token, POS tags).\n",
        "    Implementaci√≥n robusta: comprueba recursos NLTK, maneja errores y devuelve resultado parcial si hace falta.\n",
        "\n",
        "    Args:\n",
        "        oracion (str): oraci√≥n en espa√±ol (cadena)\n",
        "\n",
        "    Returns:\n",
        "        dict: {\n",
        "            'total_tokens': int,\n",
        "            'total_tipos': int,\n",
        "            'ratio_tt': float (3 decimales),\n",
        "            'pos_tags': [(token, etiqueta), ...]\n",
        "        }\n",
        "    \"\"\"\n",
        "    import nltk\n",
        "    # Asegurar recursos por si se llam√≥ a la funci√≥n en otro entorno sin ejecutar la celda 1\n",
        "    try:\n",
        "        nltk.data.find('tokenizers/punkt')\n",
        "    except LookupError:\n",
        "        nltk.download('punkt', quiet=False)\n",
        "    try:\n",
        "        nltk.data.find('taggers/averaged_perceptron_tagger')\n",
        "    except LookupError:\n",
        "        nltk.download('averaged_perceptron_tagger', quiet=False)\n",
        "\n",
        "    resultado = {\n",
        "        'total_tokens': 0,\n",
        "        'total_tipos': 0,\n",
        "        'ratio_tt': 0.0,\n",
        "        'pos_tags': []\n",
        "    }\n",
        "\n",
        "    if not isinstance(oracion, str):\n",
        "        raise ValueError(\"El argumento 'oracion' debe ser una cadena de texto.\")\n",
        "\n",
        "    try:\n",
        "        # Tokenizaci√≥n (sin language param)\n",
        "        tokens = word_tokenize(oracion)\n",
        "    except Exception as e:\n",
        "        # fallback: split simple si tokenizaci√≥n falla (no ideal, pero evita crash)\n",
        "        print(\"‚ö†Ô∏è Error en word_tokenize():\", str(e))\n",
        "        print(\"Usando fallback con simple split() para tokens.\")\n",
        "        tokens = oracion.split()\n",
        "\n",
        "    # Conteos\n",
        "    total_tokens = len(tokens)\n",
        "    total_tipos = len(set(tokens))\n",
        "    ratio_tt = round(total_tipos / total_tokens, 3) if total_tokens > 0 else 0.0\n",
        "\n",
        "    # Etiquetado POS (intentamos usar averaged_perceptron_tagger)\n",
        "    try:\n",
        "        pos_tags = pos_tag(tokens, tagset='universal')\n",
        "    except Exception as e:\n",
        "        # Si falla, devolvemos tokens sin etiquetas y avisamos\n",
        "        print(\"‚ö†Ô∏è Error en pos_tag():\", str(e))\n",
        "        print(\"Devolviendo tokens sin etiquetas POS.\")\n",
        "        pos_tags = [(t, None) for t in tokens]\n",
        "\n",
        "    resultado['total_tokens'] = total_tokens\n",
        "    resultado['total_tipos'] = total_tipos\n",
        "    resultado['ratio_tt'] = ratio_tt\n",
        "    resultado['pos_tags'] = pos_tags\n",
        "\n",
        "    return resultado"
      ],
      "metadata": {
        "id": "-kHgWpfanbYz"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CELDA 4: Pruebas con oraciones de ejemplo\n",
        "oracion_ejemplo = \"El gato negro salta alto y el perro corre r√°pido por el parque.\"\n",
        "\n",
        "res = analisis_morfologico(oracion_ejemplo)\n",
        "pprint(res)\n",
        "\n",
        "# Pruebas adicionales\n",
        "print(\"\\nPrueba adicional 1:\")\n",
        "pprint(analisis_morfologico(\"Los estudiantes estudian programaci√≥n en la universidad cada ma√±ana.\"))\n",
        "\n",
        "print(\"\\nPrueba adicional 2:\")\n",
        "pprint(analisis_morfologico(\"Hoy llueve, pero ma√±ana saldr√° el sol.\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4xaOp8Pnme6s",
        "outputId": "46ab611d-4308-488e-9787-e46e9369b5f1"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚ö†Ô∏è Error en word_tokenize(): \n",
            "**********************************************************************\n",
            "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('punkt_tab')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "Usando fallback con simple split() para tokens.\n",
            "‚ö†Ô∏è Error en pos_tag(): \n",
            "**********************************************************************\n",
            "  Resource \u001b[93maveraged_perceptron_tagger_eng\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('averaged_perceptron_tagger_eng')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtaggers/averaged_perceptron_tagger_eng/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "Devolviendo tokens sin etiquetas POS.\n",
            "{'pos_tags': [('El', None),\n",
            "              ('gato', None),\n",
            "              ('negro', None),\n",
            "              ('salta', None),\n",
            "              ('alto', None),\n",
            "              ('y', None),\n",
            "              ('el', None),\n",
            "              ('perro', None),\n",
            "              ('corre', None),\n",
            "              ('r√°pido', None),\n",
            "              ('por', None),\n",
            "              ('el', None),\n",
            "              ('parque.', None)],\n",
            " 'ratio_tt': 0.923,\n",
            " 'total_tipos': 12,\n",
            " 'total_tokens': 13}\n",
            "\n",
            "Prueba adicional 1:\n",
            "‚ö†Ô∏è Error en word_tokenize(): \n",
            "**********************************************************************\n",
            "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('punkt_tab')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "Usando fallback con simple split() para tokens.\n",
            "‚ö†Ô∏è Error en pos_tag(): \n",
            "**********************************************************************\n",
            "  Resource \u001b[93maveraged_perceptron_tagger_eng\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('averaged_perceptron_tagger_eng')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtaggers/averaged_perceptron_tagger_eng/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "Devolviendo tokens sin etiquetas POS.\n",
            "{'pos_tags': [('Los', None),\n",
            "              ('estudiantes', None),\n",
            "              ('estudian', None),\n",
            "              ('programaci√≥n', None),\n",
            "              ('en', None),\n",
            "              ('la', None),\n",
            "              ('universidad', None),\n",
            "              ('cada', None),\n",
            "              ('ma√±ana.', None)],\n",
            " 'ratio_tt': 1.0,\n",
            " 'total_tipos': 9,\n",
            " 'total_tokens': 9}\n",
            "\n",
            "Prueba adicional 2:\n",
            "‚ö†Ô∏è Error en word_tokenize(): \n",
            "**********************************************************************\n",
            "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('punkt_tab')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "Usando fallback con simple split() para tokens.\n",
            "‚ö†Ô∏è Error en pos_tag(): \n",
            "**********************************************************************\n",
            "  Resource \u001b[93maveraged_perceptron_tagger_eng\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('averaged_perceptron_tagger_eng')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtaggers/averaged_perceptron_tagger_eng/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "Devolviendo tokens sin etiquetas POS.\n",
            "{'pos_tags': [('Hoy', None),\n",
            "              ('llueve,', None),\n",
            "              ('pero', None),\n",
            "              ('ma√±ana', None),\n",
            "              ('saldr√°', None),\n",
            "              ('el', None),\n",
            "              ('sol.', None)],\n",
            " 'ratio_tt': 1.0,\n",
            " 'total_tipos': 7,\n",
            " 'total_tokens': 7}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# üîπ CELDA 5: An√°lisis breve de resultados\n",
        "# ============================================================\n",
        "\n",
        "\"\"\"\n",
        "üîç AN√ÅLISIS DE RESULTADOS:\n",
        "\n",
        "1Ô∏è‚É£ Los valores de 'total_tokens' indican la cantidad de palabras (y signos) detectados por el tokenizador.\n",
        "2Ô∏è‚É£ 'total_tipos' representa cu√°ntas palabras diferentes hay en la oraci√≥n.\n",
        "3Ô∏è‚É£ El 'ratio_tt' (tipos/tokens) mide la diversidad l√©xica:\n",
        "    - Valores cercanos a 1 indican una oraci√≥n con muchas palabras √∫nicas.\n",
        "    - Valores m√°s bajos indican repeticiones o vocabulario limitado.\n",
        "4Ô∏è‚É£ Las etiquetas POS proporcionan la categor√≠a gramatical de cada palabra (sustantivo, verbo, adjetivo, etc.).\n",
        "\n",
        "En general, el an√°lisis morfol√≥gico permite observar la estructura gramatical y la variedad del vocabulario de un texto.\n",
        "\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "id": "OxB7yFr1mjhJ",
        "outputId": "f70ba0f6-1fb3-4df7-e5ed-d1567e0125a0"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\nüîç AN√ÅLISIS DE RESULTADOS:\\n\\n1Ô∏è‚É£ Los valores de 'total_tokens' indican la cantidad de palabras (y signos) detectados por el tokenizador.\\n2Ô∏è‚É£ 'total_tipos' representa cu√°ntas palabras diferentes hay en la oraci√≥n.\\n3Ô∏è‚É£ El 'ratio_tt' (tipos/tokens) mide la diversidad l√©xica: \\n    - Valores cercanos a 1 indican una oraci√≥n con muchas palabras √∫nicas.\\n    - Valores m√°s bajos indican repeticiones o vocabulario limitado.\\n4Ô∏è‚É£ Las etiquetas POS proporcionan la categor√≠a gramatical de cada palabra (sustantivo, verbo, adjetivo, etc.).\\n\\nEn general, el an√°lisis morfol√≥gico permite observar la estructura gramatical y la variedad del vocabulario de un texto.\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    }
  ]
}