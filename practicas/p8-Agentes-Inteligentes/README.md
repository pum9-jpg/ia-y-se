# üßπ Simulaci√≥n del Mundo de la Aspiradora

## üìò Descripci√≥n General

Este programa implementa una simulaci√≥n cl√°sica del **mundo de la aspiradora**, un problema introductorio en el campo de la **Inteligencia Artificial**.  
El objetivo es comparar el desempe√±o de dos tipos de agentes:

1. **Agente Reactivo Simple** ‚Üí act√∫a √∫nicamente seg√∫n su percepci√≥n inmediata.  
2. **Agente Basado en Modelos** ‚Üí utiliza un modelo interno del entorno para decidir mejor sus acciones.

La simulaci√≥n se desarrolla en un entorno con **dos habitaciones (A y B)**, que pueden estar **limpias o sucias**.  
El agente se mueve, aspira y obtiene una puntuaci√≥n de rendimiento seg√∫n sus acciones.

---

## ‚öôÔ∏è Estructura del C√≥digo

El c√≥digo est√° compuesto por **tres clases principales** y una secci√≥n de ejecuci√≥n.

### 1. `EntornoAspiradora`
Representa el entorno donde se mueve el agente.

#### Atributos
- `estado_habitaciones`: diccionario con el estado de cada habitaci√≥n (`Limpia` o `Sucia`).
- `ubicacion_agente`: indica si el agente est√° en la habitaci√≥n A o B.
- `pasos`: n√∫mero de acciones ejecutadas.
- `rendimiento`: puntuaci√≥n total acumulada.

#### M√©todos
- `obtener_percepcion()`: devuelve la percepci√≥n actual `(ubicaci√≥n, estado)`.
- `ejecutar_accion(accion)`: aplica la acci√≥n del agente y actualiza el entorno y el rendimiento.
- `esta_limpio()`: verifica si todas las habitaciones est√°n limpias.
- `simular(agente, max_pasos=10)`: ejecuta la simulaci√≥n completa hasta que el entorno est√© limpio o se alcance el n√∫mero m√°ximo de pasos.

#### Reglas de rendimiento
| Acci√≥n | Condici√≥n | Cambio en rendimiento |
|--------|------------|-----------------------|
| `aspirar` | Si la habitaci√≥n est√° sucia | +10 |
| `aspirar` | Si la habitaci√≥n ya est√° limpia | -1 |
| `ir_a_B` o `ir_a_A` | Movimiento entre habitaciones | -1 |
| `no_hacer_nada` | No afecta el rendimiento | 0 |

---

### 2. `AgenteReactivoSimple`
Decide su acci√≥n solo seg√∫n la percepci√≥n actual, sin recordar estados pasados.

#### L√≥gica de decisi√≥n:
1. Si la habitaci√≥n est√° sucia ‚Üí **aspira**  
2. Si est√° limpia y est√° en A ‚Üí **va a B**  
3. Si est√° limpia y est√° en B ‚Üí **va a A**

---

### 3. `AgenteBasadoEnModelos`
Mantiene un **modelo interno del entorno** (qu√© sabe de cada habitaci√≥n) y decide con base en esa informaci√≥n.

#### L√≥gica de decisi√≥n:
1. Actualiza el modelo con la percepci√≥n actual.  
2. Si la habitaci√≥n actual est√° sucia ‚Üí **aspira**.  
3. Si sabe que alguna habitaci√≥n est√° sucia ‚Üí **se dirige hacia ella**.  
4. Si todo est√° limpio ‚Üí **no hace nada**.  

Este agente tiene memoria y puede evitar acciones innecesarias.

---

## ‚ñ∂Ô∏è Ejecuci√≥n de la Simulaci√≥n

En la parte final del archivo se ejecutan dos simulaciones independientes:

```python
print("\n--- Probando Agente Reactivo Simple ---")
entorno1 = EntornoAspiradora()
agente1 = AgenteReactivoSimple()
entorno1.simular(agente1)

print("\n--- Probando Agente Basado en Modelos ---")
entorno2 = EntornoAspiradora()
agente2 = AgenteBasadoEnModelos()
entorno2.simular(agente2)
```

Cada agente comienza con un entorno generado aleatoriamente y se ejecuta hasta 10 pasos como m√°ximo.

---

## üß© Ejemplo de Salida

```text
--- Probando Agente Reactivo Simple ---
Estado Inicial: {'A': 'Sucia', 'B': 'Limpia'}, Agente en: A

Paso 1: Percepci√≥n: ('A', 'Sucia'), Acci√≥n: aspirar
Paso 2: Percepci√≥n: ('A', 'Limpia'), Acci√≥n: ir_a_B

Simulaci√≥n terminada en 2 pasos.
Rendimiento Final: 9
Estado Final: {'A': 'Limpia', 'B': 'Limpia'}
```

---

## üíª Compilaci√≥n y Ejecuci√≥n

Este c√≥digo est√° escrito en **Python 3**, por lo que **no requiere compilaci√≥n**.  
Solo necesitas tener Python instalado en tu sistema.

### üîß Requisitos
- Python 3.8 o superior
- M√≥dulo est√°ndar `random` (ya incluido en Python)

### üöÄ Ejecuci√≥n
1. Guarda el c√≥digo en un archivo llamado `aspiradora.py`.
2. Abre la terminal o consola en el directorio donde guardaste el archivo.
3. Ejecuta el siguiente comando:

```bash
python aspiradora.py
```

### üí° Nota
Cada ejecuci√≥n generar√° un entorno diferente debido al uso del m√≥dulo `random`.

---

## üß† Conclusi√≥n

Este experimento muestra c√≥mo distintos tipos de agentes pueden actuar en un mismo entorno:
- El **agente reactivo** responde sin memoria, por lo que puede repetir errores.
- El **agente basado en modelos** recuerda lo que ha percibido, siendo m√°s eficiente.

Ambos son ejemplos de **agentes inteligentes**, pero con distintos niveles de complejidad y desempe√±o.

---
